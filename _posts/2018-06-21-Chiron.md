**题目： Chiron: Privacy-preserving Machine Learning as a Service**

**作者： Tyler Hunt, Congzheng Song, Reza Shokri, Vitaly Shmatikov, Emmett Witchel**

**单位： The University of Texas at Austin, Cornell University and National University of Singapore**

**出版： arXiv:1803.05961**

本工作来自德州奥斯汀的Emmett Witchel团队。一作是[Ryoan](https://www.usenix.org/conference/osdi16/technical-sessions/presentation/hunt)的作者。

# 综述：
*    现有的云平台提供ML机器学习服务，让没有ML开发经验的客户可以直接在基础平台上训练，获得预测模型。这种平台要求用户将训练数据暴露给服务提供者。
*    Chiron考虑了ML训练过程中的隐私问题：不但保护了训练算法，同时保护了模型结构，给外部攻击者提供黑盒模型。
*    Chiron结合了SGX，使用标准工具链（Theano框架和C编译器），模型创建代码使用了Ryoan沙盒（NaCl变种）。为了提供分布式训练，Chiron并发运行多个Enclave，使用一个参数服务器来交换数据。


# 矛盾阐释：
* 公有云ML的矛盾之处在于，客户提供了训练数据，而ML服务操作者提供了训练代码。二者来自不同客体，彼此互不信任，因此需要对代码的执行进行限制、省察，确保数据隐私性不被破坏。

# 背景：

1.    深度学习：在现代ML任务中被广泛使用，特别是在计算机视觉和图像识别领域。层与层之间连接的拓扑结构很大程度上决定了模型的精度。在大规模数据集上使用神经网络训练历史悠久。延展的方法是数据和模型的并行化，即多个模型同时训练，再借助一个参数服务器来交换参数；将训练数据分成若干子类，每个模型单独作用在子类上。参数服务器全局可访问，属于典型的分布式—单master多worker 模型。
2.    本文将 模型设计 从 模型训练 概念中分开，模型设计包括了模型类型和拓扑结构、损失函数、优化算法以及超参数值、输入数据的变换（延展、旋转或再抽样）。模型训练指代对数据的反复作用过程，包括批处理、计算损失和参数更新。
3.    符号计算：大量ML算法是基于数学矩阵运算的，这些操作和数据无关，可以直接符号化定义。因此计算模型被等价为图计算，将常用的加法和点积作为内部节点，数据作为输入元，经过图的一系列变换后得出输出元。
4.    MLaS：ML即服务。各大云ML平台提供API，用户上传数据后返回训练模型。通常用户不知道训练细节，如Google隐藏全部细节，Amazon允许用户调整超参数、选择归一化方式和迭代次数。**本文将训练方法视为服务商的知识产权，而训练数据作为用户财产，二者互不泄露**。
5.    SGX：远程验证作为衡量enclave是否安全的首要方法。Rollback攻击：SGX并不对freshness做保证，必须依赖额外的硬件计数器（Intel ME SPI Flash）；indistinguishably：**SGX无法对同一平台上的多个重复实例做区分（远程验证只检查初始状态是否合格，不对实例做记录），需要额外引入新的机制**。
6.    Ryoan：利用沙盒对Enclave中的代码运行进行限制，利用审计的方法来查看运行的正确性。


# 威胁模型：

1.    面向MLaS平台，假设训练模型和部署作用在同一物理计算资源上。只要模型还在训练，数据就必须维持保密性。对模型和输出的查询在模型使用时必须保密。
    假设整个计算平台不可信，攻击者试图抽取训练数据的秘密。
2.    TCB：用户和服务商都相信Ryoan沙盒代码，本工作对Ryoan做了修改，使其可以协商多个enclave。双方都相信可信硬件SGX。使用标准化工具链，相信工具链自身不会有意泄露数据。
3.    威胁者访问模型：**训练模型可能被恶意设计，由此泄露隐私（如深度神经网络具备强记忆性），这些威胁还未被很好认识，也缺乏通用有效的防护机制**。Chiron将模型加载到一个特殊的Enclave中，保证攻击者（包括服务提供者）无法挂测用户的查询。



# 设计：

* 引入Training Enclave，并对内部代码进行了权限分离。Ryoan为图中的Admin Code，服务提供商的代码被严格规约和限制。
* 为了区分不同的enclave，首先将数据全部存在中央参数服务器上，每个Training Enclave给服务器发生自己的公钥，服务器派发随机的nonce。用户可以比较公钥，如果存在相同的公钥，则运行两个相同实例，那么中央服务器就拒绝发送数据。

执行过程：见原文图4。

安全信道：Enclave间的信道建立以来AES-GCM和authenticated key agreement protocol，由此提供端到端的隐私保护。

# 实现：

    对LibC做修改，对系统调用参数做和返回值做Marshall。声称可以防御所有已有Iago攻击。
    用libclang和llvm执行引擎（clang解释器）代替gcc，避免代码生成时写入文件泄露模型的构建信息。
    使用Redis Key-Value Store作为参数服务器。该服务器对所有会话的公钥做记录，用于区分Training Enclave。**为了计算epoch，使用平台上的时间（nanosleep）。本文认为提供不一致时间为拒绝服务**。
    对于超过EPC内存限制的训练数据，Chiron引入流处理，将输入数据以固定频率分成可配置的特定chunk，对于具体的分块策略，留作未来工作。


# 不足：

1.    侧信道：cache-timing and memory-access channels，对于页表访问，可以在代码生成时将训练算法转换为oblivious；也有其他工作使用TSX来避免数据访问模型被观测。
2.    **不支持GPU**


# 体会：

1.    云上结合隐私的数据训练、分析平台工作已有不少，如VC3（MapReduce）、Ryoan（分布式沙盒）。不同的是，VC3假设Enclave内部的代码全可信，Ryoan并没有和现有ML工具链结合。本文可以理解为在Ryoan基础之上，添加了ML工具链代码的集成以及与参数服务器的协作。
2.    本文使用了不可信时间戳。时间问题是未来一个重点关注对象。
3.    **SGX-enabled CPU和GPU的可信路径工作值得继续探索**。
4.    本文因需要使用SGX V2指令集，因此只能模拟评估结果，评估数据参考意义较低。
